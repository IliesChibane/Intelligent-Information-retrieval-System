{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Informarion Retrival Project</h1></center>\n",
    "<center><h1>Build an Intelligent Information Retrival System</h1></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies et du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from metric_tools import compute_metrics\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>told</th>\n",
       "      <th>biographi</th>\n",
       "      <th>briefli</th>\n",
       "      <th>describ</th>\n",
       "      <th>system</th>\n",
       "      <th>attempt</th>\n",
       "      <th>provid</th>\n",
       "      <th>decim</th>\n",
       "      <th>detail</th>\n",
       "      <th>...</th>\n",
       "      <th>anglo</th>\n",
       "      <th>supposit</th>\n",
       "      <th>morn</th>\n",
       "      <th>claus</th>\n",
       "      <th>inventor</th>\n",
       "      <th>sell</th>\n",
       "      <th>patente</th>\n",
       "      <th>monopoli</th>\n",
       "      <th>15%</th>\n",
       "      <th>9%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565909</td>\n",
       "      <td>0.64087</td>\n",
       "      <td>0.672031</td>\n",
       "      <td>0.410718</td>\n",
       "      <td>0.201332</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>0.275780</td>\n",
       "      <td>0.209136</td>\n",
       "      <td>0.982483</td>\n",
       "      <td>0.29727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097293</td>\n",
       "      <td>0.183853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>1.054883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 6929 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            18     told  biographi   briefli   describ    system   attempt  \\\n",
       "0     0.565909  0.64087   0.672031  0.410718  0.201332  0.145940  0.275780   \n",
       "1     0.000000  0.00000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.00000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.00000   0.000000  0.000000  0.000000  0.116752  0.000000   \n",
       "4     0.000000  0.00000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...      ...        ...       ...       ...       ...       ...   \n",
       "1455  0.000000  0.00000   0.000000  0.000000  0.000000  0.233504  0.000000   \n",
       "1456  0.000000  0.00000   0.000000  0.000000  0.000000  0.097293  0.183853   \n",
       "1457  0.000000  0.00000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1458  0.000000  0.00000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1459  0.000000  0.00000   0.000000  0.000000  0.000000  0.194587  0.000000   \n",
       "\n",
       "        provid     decim   detail  ...     anglo  supposit      morn  \\\n",
       "0     0.209136  0.982483  0.29727  ...  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000   \n",
       "3     0.167309  0.000000  0.00000  ...  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000   \n",
       "...        ...       ...      ...  ...       ...       ...       ...   \n",
       "1455  0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000   \n",
       "1456  0.000000  0.000000  0.00000  ...  0.527442  0.000000  0.000000   \n",
       "1457  0.000000  0.000000  0.00000  ...  0.000000  1.054883  1.054883   \n",
       "1458  0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000   \n",
       "1459  0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "         claus  inventor      sell   patente  monopoli       15%        9%  \n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1455  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1456  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1457  1.054883  1.054883  1.054883  1.054883  1.054883  0.000000  0.000000  \n",
       "1458  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1459  0.000000  0.000000  0.000000  0.000000  0.000000  1.054883  1.054883  \n",
       "\n",
       "[1460 rows x 6929 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../csv_docs/dataset_dbscan.csv\")\n",
    "df.drop(columns = df.columns[0], axis = 1, inplace= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_inverse = pd.read_csv(\"../fichier_inverse.csv\")\n",
    "fichier_inverse = fichier_inverse.drop(\"Unnamed: 0\", axis=1)\n",
    "fichier_inverse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterisation des documents avec DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retourner tous les points du dataset qui sont à une distance inférieure à eps de notre instance\n",
    "def region_query(distances, i, eps):\n",
    "    doc_indexes = np.where(distances[i] <= eps)[0] # On récupère les index des points qui sont à une distance inférieure à eps\n",
    "    return [i for i in doc_indexes] # On retourne la liste des index des points\n",
    "\n",
    "# Fonction qui permet de récursivement ajouter les points voisins à notre cluster\n",
    "def expand_cluster(distances, document_cluster, clusters, C, neighbors, eps, min_pts):\n",
    "    while len(neighbors)!=0: # Tant qu'il y a des voisins\n",
    "        index_doc = neighbors.pop() # On récupère le premier voisin\n",
    "        if index_doc == 1459: index_doc = 1458\n",
    "        if document_cluster[index_doc] >=0 : continue # Si le point appartient déjà à un cluster et n'est pas du bruit, on passe au suivant\n",
    "        document_cluster[index_doc] = C # On change la valeur -1 par le numéro du cluster pour indiquer que le point appartient à ce cluster\n",
    "        clusters[C].append(index_doc) # On ajoute le point au cluster\n",
    "        new_neighbors = region_query(distances,index_doc,eps) # On récupère les points voisins du point\n",
    "        if len(new_neighbors)>= min_pts: neighbors.extend(new_neighbors) # Si le point a assez de voisins, on ajoute les voisins au cluster\n",
    "\n",
    "# Fonction recréant l'algorithme DBSCAN\n",
    "def dbscan(distances, eps, min_pts):\n",
    "    # On itilisalise une liste a -1 pour chaque point du dataset (on ne connait pas encore son cluster)\n",
    "    document_cluster = np.full(len(distances), (-1), dtype = np.int)\n",
    "    clusters = [[]]\n",
    "    noise = []\n",
    "    C = 0\n",
    "    for index_doc in range(len(distances)):\n",
    "        if document_cluster[index_doc] != -1 : continue # Si le point appartient déjà à un cluster, on passe au suivant\n",
    "        \n",
    "        neighbors = region_query(distances,index_doc,eps) # On récupère les points voisins\n",
    "        \n",
    "        if len(neighbors) >= min_pts: # Si le point a assez de voisins, on crée un nouveau cluster\n",
    "            document_cluster[index_doc] = C # On change la valeur -1 par le numéro du cluster pour indiquer que le point appartient à ce cluster\n",
    "            clusters[C].append(index_doc) # On ajoute le point au cluster\n",
    "            expand_cluster(distances, document_cluster, clusters, C, neighbors, eps, min_pts) # On ajoute les voisins du point au cluster\n",
    "            C += 1 # On passe au cluster suivant\n",
    "            clusters.append([])  # On initialise le nouveau cluster\n",
    "        else : # Si le point n'a pas assez de voisins, on le considère comme du bruit\n",
    "            document_cluster[index_doc] = -2 # On change la valeur -1 par -2 pour indiquer que le point est du bruit\n",
    "            noise.append(index_doc) # On ajoute le point au bruit\n",
    "\n",
    "            \n",
    "    del clusters[C] # On supprime le dernier cluster qui est vide\n",
    "    \n",
    "    return clusters, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la distance de manhattan entre tout les points du dataset\n",
    "# Pour économiser du temps d'execution, on ne calcule que la matrice superieure de la matrice de distance\n",
    "def manhattan_distance(df):\n",
    "    distances = np.zeros((len(df), len(df)))\n",
    "    for i in range(len(df)):\n",
    "        for j in range(i+1, len(df)):\n",
    "            dist = np.sum(np.abs(df[i] - df[j]))\n",
    "            \n",
    "            distances[i][j] = dist\n",
    "            distances[j][i] = dist\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Fonction qui permet de calculer la distance de manhattan entre deux vecteurs en prenant en compte les valeurs communes\n",
    "def manhattan_distance_with_coeff(df):\n",
    "    distances = np.zeros((len(df), len(df))) # On initialise la matrice de distance\n",
    "    for i in range(len(df)): # On parcourt tous les points du dataset\n",
    "        for j in range(i+1, len(df)): # On parcourt tous les points du dataset\n",
    "            \n",
    "            index_a = np.where(df[i]>0)[0] # On récupère les index des valeurs non nulles du vecteur a\n",
    "            index_b = np.where(df[j]>0)[0] # On récupère les index des valeurs non nulles du vecteur b\n",
    "            common = np.intersect1d(index_a, index_b) # On récupère les index des valeurs communes\n",
    "            \n",
    "            # On multiplie par 5 le poid des valeurs non communes (Pour éloigner les documents avec beaucoup de valeurs non communes)\n",
    "            new_a = df[i] * 5 \n",
    "            new_b = df[j] * 5\n",
    "            \n",
    "            # On divise par 100 le poid des valeurs communes (Pour rapprocher les documents avec beaucoup de valeurs communes)\n",
    "            new_a[common] = df[i][common] * 0.01\n",
    "            new_b[common] = df[j][common] * 0.01\n",
    "            \n",
    "            dist = np.sum(np.abs(new_a - new_b)) # On calcule la distance de manhattan\n",
    "            \n",
    "            # On divise par le nombre de valeurs communes si il y en a plus que de valeurs non communes (Toujours pour rapprocher les documents avec beaucoup de valeurs communes)\n",
    "            if len(common) > len(df[i]) - len(common): dist = dist / len(common) \n",
    "            else: dist = dist * (len(df[i]) - len(common)) # On multiplie par le nombre de valeurs non communes si il y en a plus que de valeurs communes (Toujours pour éloigner les documents avec beaucoup de valeurs non communes)\n",
    "            \n",
    "            # On met la distance entre le document i et le document j et la distance entre le document j et le document i à la même valeur\n",
    "            distances[i][j] = dist \n",
    "            distances[j][i] = dist \n",
    "\n",
    "# Fonction qui permet de calculer la distance de Dice entre deux documents\n",
    "def dice_distance(fichier_inverse):\n",
    "    distances = None\n",
    "    for d in sorted(fichier_inverse[\"Document\"].unique()):\n",
    "        words = list(fichier_inverse.loc[fichier_inverse[\"Document\"] == d, \"Word\"].unique()) # Liste des mots du document d\n",
    "        df = fichier_inverse.loc[fichier_inverse[\"Word\"].isin(words),[\"Document\",\"Word\",\"Poid\"]] # On récupère les documents qui ont au moins un mot en commun avec le document d\n",
    "        df = df.loc[df[\"Document\"] != d, :] # On supprime le document d\n",
    "        n = df.groupby('Document')['Word'].count().to_frame() # on compte le nombre de mots par document\n",
    "        df = df.groupby('Document')['Poid'].sum().to_frame() # on somme les poids des mots de la requête\n",
    "        df.reset_index(inplace=True) # on remet les documents en colonne\n",
    "        df.rename(columns = {'Poid':'Scalar weight'}, inplace = True)  # on renomme la colonne\n",
    "\n",
    "\n",
    "        weights_doc = fichier_inverse.copy() # on copie le fichier inverse\n",
    "\n",
    "        weights_doc[\"Poid\"] = np.power(weights_doc[\"Poid\"], 2) # on calcule le carré des poids\n",
    "\n",
    "        weights_doc = weights_doc.groupby('Document')['Poid'].sum().to_frame() # on somme les carrés des poids\n",
    "\n",
    "        weights_doc.rename(columns = {'Poid':'weight docs'}, inplace = True) # on renomme la colonne\n",
    "        \n",
    "        df = df.merge(weights_doc, on=\"Document\") # on fusionne les deux dataframes\n",
    "\n",
    "        df[\"weight doc\"] = n.to_numpy() # on ajoute la colonne du nombre de mots du document d\n",
    "        \n",
    "        df[\"RSV\"] = np.divide( # on divise le poids de la requête par le produit des racines carrées des poids de la requête et du document\n",
    "                            np.multiply(df[\"Scalar weight\"], 2),\n",
    "                            np.add(df[\"weight doc\"], df[\"weight docs\"]))\n",
    "\n",
    "        df = df[[\"Document\", \"RSV\"]]\n",
    "        df[\"Document\"] = df[\"Document\"].apply(lambda x: x.split(\"D\")[1]) # on supprime l'extension du nom du document\n",
    "        df[\"Document\"] = df[\"Document\"].astype(int) # on convertit le nom du document en entier\n",
    "        for i in range(1, 1460):\n",
    "            if i not in df[\"Document\"].unique():\n",
    "                df = df.append({\"Document\": i, \"RSV\": 0}, ignore_index=True)\n",
    "        df[\"RSV\"] = 1 - df[\"RSV\"] # on inverse les valeurs\n",
    "        df.rename(columns = {'RSV': d}, inplace = True) # on renomme la colonne\n",
    "        df = df.sort_values(by=[\"Document\"]) # on trie les documents par poids\n",
    "        \n",
    "        # on fusionne les dataframes\n",
    "        if distances is None: \n",
    "            distances = df\n",
    "        else: \n",
    "            distances = distances.merge(df, on=\"Document\")\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.drop(\"Document\", axis=1, inplace=True)\n",
    "distances.to_csv(\"../distances.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.94211934, 0.79439579, ..., 0.85990716, 0.95986786,\n",
       "        0.93106985],\n",
       "       [1.        , 0.73805684, 0.81522626, ..., 0.79508038, 0.79508038,\n",
       "        0.95218339],\n",
       "       [0.9248936 , 0.91205711, 0.72949473, ..., 1.        , 0.84442234,\n",
       "        0.87858377],\n",
       "       ...,\n",
       "       [0.75408656, 0.76757146, 0.71112712, ..., 0.823416  , 0.75504815,\n",
       "        0.91217535],\n",
       "       [1.        , 0.92878937, 0.87523715, ..., 0.98427099, 0.94055683,\n",
       "        1.        ],\n",
       "       [1.        , 0.88525502, 0.9049204 , ..., 1.        , 1.        ,\n",
       "        0.9542612 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = pd.read_csv(\"../distances.csv\").to_numpy()\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcule_distances(df, methode):\n",
    "    if methode == \"manhattan\": return manhattan_distance(df)\n",
    "    elif methode == \"manhattan_with_coeff\": return manhattan_distance_with_coeff(df)\n",
    "    elif methode == \"dice\": return dice_distance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = calcule_distances(df.to_numpy(), methode = \"manhattan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = dbscan(distances, 50, 3)\n",
    "len(clusters), len(clusters[0]), len(clusters[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat insufisant essayons une autre méthode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN après nettoyage et réduction des dimmensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.07% of the columns are numbers\n"
     ]
    }
   ],
   "source": [
    "number_cols = [x for x in df.columns if re.search(r'\\d', x)] # On récupère les colonnes contenant des chiffres\n",
    "percent_num = 100 * len(number_cols) / len(df.columns) # On calcule le pourcentage de colonnes contenant des chiffres\n",
    "\n",
    "print(f\"{percent_num:.2f}% of the columns are numbers\") # On affiche le pourcentage de colonnes contenant des chiffres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs numérique représentant souvent un problème lors du clustering en text mining nous allons les supprimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 6929), (1460, 6439))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.copy() # On copie le dataset\n",
    "for c in number_cols:\n",
    "    df_clean.drop(c, axis=1, inplace=True)\n",
    "df.shape, df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On applique PCA pour la réduction de dimension\n",
    "def pca_decomp(df, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(df)\n",
    "    df_pca = pca.transform(df)\n",
    "    df_pca = pd.DataFrame(df_pca)\n",
    "    return pca, df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.162223</td>\n",
       "      <td>-0.033614</td>\n",
       "      <td>-0.053589</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>-0.114503</td>\n",
       "      <td>0.329911</td>\n",
       "      <td>-0.199963</td>\n",
       "      <td>-0.123973</td>\n",
       "      <td>0.063422</td>\n",
       "      <td>-0.226674</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>-0.385038</td>\n",
       "      <td>-0.452281</td>\n",
       "      <td>0.226566</td>\n",
       "      <td>-0.004534</td>\n",
       "      <td>-0.245701</td>\n",
       "      <td>-0.019607</td>\n",
       "      <td>-0.145216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.179292</td>\n",
       "      <td>-0.030928</td>\n",
       "      <td>0.117684</td>\n",
       "      <td>-0.068651</td>\n",
       "      <td>-0.049815</td>\n",
       "      <td>-0.123002</td>\n",
       "      <td>-0.085362</td>\n",
       "      <td>0.110274</td>\n",
       "      <td>-0.144923</td>\n",
       "      <td>0.073120</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>-0.067145</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.204324</td>\n",
       "      <td>0.045420</td>\n",
       "      <td>-0.019613</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>0.075375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097130</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>-0.096119</td>\n",
       "      <td>0.073564</td>\n",
       "      <td>-0.107068</td>\n",
       "      <td>-0.039025</td>\n",
       "      <td>-0.087303</td>\n",
       "      <td>-0.093104</td>\n",
       "      <td>0.174473</td>\n",
       "      <td>-0.152964</td>\n",
       "      <td>-0.169245</td>\n",
       "      <td>0.184608</td>\n",
       "      <td>0.233656</td>\n",
       "      <td>0.326478</td>\n",
       "      <td>-0.023966</td>\n",
       "      <td>0.099233</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.234494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.334562</td>\n",
       "      <td>-0.073451</td>\n",
       "      <td>0.338164</td>\n",
       "      <td>0.014805</td>\n",
       "      <td>-0.087599</td>\n",
       "      <td>-0.063102</td>\n",
       "      <td>-0.097407</td>\n",
       "      <td>0.123036</td>\n",
       "      <td>-0.150240</td>\n",
       "      <td>0.135655</td>\n",
       "      <td>0.216837</td>\n",
       "      <td>-0.059363</td>\n",
       "      <td>-0.075760</td>\n",
       "      <td>-0.062396</td>\n",
       "      <td>-0.020201</td>\n",
       "      <td>-0.137768</td>\n",
       "      <td>-0.005336</td>\n",
       "      <td>0.127807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.181677</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.157628</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>-0.068232</td>\n",
       "      <td>-0.043263</td>\n",
       "      <td>-0.055391</td>\n",
       "      <td>-0.056023</td>\n",
       "      <td>0.029057</td>\n",
       "      <td>0.172292</td>\n",
       "      <td>-0.207354</td>\n",
       "      <td>0.077441</td>\n",
       "      <td>-0.185084</td>\n",
       "      <td>0.108879</td>\n",
       "      <td>-0.135967</td>\n",
       "      <td>0.377507</td>\n",
       "      <td>0.122138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>-0.251296</td>\n",
       "      <td>-0.021151</td>\n",
       "      <td>-0.183376</td>\n",
       "      <td>0.063802</td>\n",
       "      <td>-0.082389</td>\n",
       "      <td>-0.064080</td>\n",
       "      <td>-0.017167</td>\n",
       "      <td>-0.107319</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>-0.002508</td>\n",
       "      <td>-0.011048</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>0.239036</td>\n",
       "      <td>0.114347</td>\n",
       "      <td>-0.068869</td>\n",
       "      <td>-0.140871</td>\n",
       "      <td>0.123538</td>\n",
       "      <td>-0.164210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-0.468562</td>\n",
       "      <td>-0.018169</td>\n",
       "      <td>0.207268</td>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.046632</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>-0.163787</td>\n",
       "      <td>-0.020365</td>\n",
       "      <td>-0.099589</td>\n",
       "      <td>0.098363</td>\n",
       "      <td>0.217157</td>\n",
       "      <td>-0.015091</td>\n",
       "      <td>-0.019506</td>\n",
       "      <td>0.105928</td>\n",
       "      <td>-0.092057</td>\n",
       "      <td>-0.072380</td>\n",
       "      <td>-0.027214</td>\n",
       "      <td>0.015909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>-0.312476</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>-0.332695</td>\n",
       "      <td>0.066071</td>\n",
       "      <td>-0.074216</td>\n",
       "      <td>-0.065505</td>\n",
       "      <td>-0.112986</td>\n",
       "      <td>-0.053991</td>\n",
       "      <td>0.157507</td>\n",
       "      <td>-0.073056</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.247348</td>\n",
       "      <td>-0.320581</td>\n",
       "      <td>-0.203360</td>\n",
       "      <td>0.209855</td>\n",
       "      <td>-0.344610</td>\n",
       "      <td>-0.008101</td>\n",
       "      <td>0.416613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.075219</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>-0.175098</td>\n",
       "      <td>0.087011</td>\n",
       "      <td>-0.240106</td>\n",
       "      <td>0.143484</td>\n",
       "      <td>-0.180987</td>\n",
       "      <td>0.242727</td>\n",
       "      <td>0.141662</td>\n",
       "      <td>0.105313</td>\n",
       "      <td>0.056728</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.068940</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>-0.099034</td>\n",
       "      <td>0.270660</td>\n",
       "      <td>-0.092483</td>\n",
       "      <td>0.053720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.144390</td>\n",
       "      <td>0.024372</td>\n",
       "      <td>-0.605953</td>\n",
       "      <td>-0.279374</td>\n",
       "      <td>0.351390</td>\n",
       "      <td>-0.425392</td>\n",
       "      <td>0.488419</td>\n",
       "      <td>-0.255688</td>\n",
       "      <td>0.302126</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>-0.090992</td>\n",
       "      <td>-0.464679</td>\n",
       "      <td>-0.271106</td>\n",
       "      <td>0.644583</td>\n",
       "      <td>0.051778</td>\n",
       "      <td>0.043621</td>\n",
       "      <td>0.220037</td>\n",
       "      <td>-0.101202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.162223 -0.033614 -0.053589  0.019592 -0.114503  0.329911 -0.199963   \n",
       "1    -0.179292 -0.030928  0.117684 -0.068651 -0.049815 -0.123002 -0.085362   \n",
       "2    -0.097130  0.028816 -0.096119  0.073564 -0.107068 -0.039025 -0.087303   \n",
       "3    -0.334562 -0.073451  0.338164  0.014805 -0.087599 -0.063102 -0.097407   \n",
       "4    -0.181677 -0.001064  0.004972  0.157628  0.016384 -0.068232 -0.043263   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1455 -0.251296 -0.021151 -0.183376  0.063802 -0.082389 -0.064080 -0.017167   \n",
       "1456 -0.468562 -0.018169  0.207268  0.043093  0.046632  0.001016 -0.163787   \n",
       "1457 -0.312476  0.017380 -0.332695  0.066071 -0.074216 -0.065505 -0.112986   \n",
       "1458  0.075219  0.011570 -0.175098  0.087011 -0.240106  0.143484 -0.180987   \n",
       "1459  0.144390  0.024372 -0.605953 -0.279374  0.351390 -0.425392  0.488419   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -0.123973  0.063422 -0.226674  0.003254 -0.385038 -0.452281  0.226566   \n",
       "1     0.110274 -0.144923  0.073120  0.023499 -0.067145  0.019826  0.204324   \n",
       "2    -0.093104  0.174473 -0.152964 -0.169245  0.184608  0.233656  0.326478   \n",
       "3     0.123036 -0.150240  0.135655  0.216837 -0.059363 -0.075760 -0.062396   \n",
       "4    -0.055391 -0.056023  0.029057  0.172292 -0.207354  0.077441 -0.185084   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1455 -0.107319 -0.003510 -0.002508 -0.011048  0.044558  0.239036  0.114347   \n",
       "1456 -0.020365 -0.099589  0.098363  0.217157 -0.015091 -0.019506  0.105928   \n",
       "1457 -0.053991  0.157507 -0.073056  0.009885  0.247348 -0.320581 -0.203360   \n",
       "1458  0.242727  0.141662  0.105313  0.056728  0.025552  0.068940  0.085618   \n",
       "1459 -0.255688  0.302126  0.055340 -0.090992 -0.464679 -0.271106  0.644583   \n",
       "\n",
       "            14        15        16        17  \n",
       "0    -0.004534 -0.245701 -0.019607 -0.145216  \n",
       "1     0.045420 -0.019613 -0.008030  0.075375  \n",
       "2    -0.023966  0.099233  0.053200  0.234494  \n",
       "3    -0.020201 -0.137768 -0.005336  0.127807  \n",
       "4     0.108879 -0.135967  0.377507  0.122138  \n",
       "...        ...       ...       ...       ...  \n",
       "1455 -0.068869 -0.140871  0.123538 -0.164210  \n",
       "1456 -0.092057 -0.072380 -0.027214  0.015909  \n",
       "1457  0.209855 -0.344610 -0.008101  0.416613  \n",
       "1458 -0.099034  0.270660 -0.092483  0.053720  \n",
       "1459  0.051778  0.043621  0.220037 -0.101202  \n",
       "\n",
       "[1460 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca, df_pca = pca_decomp(df_clean, 18)\n",
    "df_pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(pca.n_components_), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = calcule_distances(df_pca.to_numpy(), methode = \"manhattan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 40)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = dbscan(distances, 4, 3)\n",
    "len(clusters), len(clusters[0]), len(clusters[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats toujours non satisfaisant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN après feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection en utilisant les poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Poid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>librari</td>\n",
       "      <td>198.338388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inform</td>\n",
       "      <td>169.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system</td>\n",
       "      <td>147.625983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use</td>\n",
       "      <td>115.767955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>index</td>\n",
       "      <td>105.729013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924</th>\n",
       "      <td>nonrandomli</td>\n",
       "      <td>0.210977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>levi</td>\n",
       "      <td>0.117209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6926</th>\n",
       "      <td>newberri</td>\n",
       "      <td>0.117209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6927</th>\n",
       "      <td>linda</td>\n",
       "      <td>0.117209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>nonacadem</td>\n",
       "      <td>0.117209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6929 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word        Poid\n",
       "0         librari  198.338388\n",
       "1          inform  169.964706\n",
       "2          system  147.625983\n",
       "3             use  115.767955\n",
       "4           index  105.729013\n",
       "...           ...         ...\n",
       "6924  nonrandomli    0.210977\n",
       "6925         levi    0.117209\n",
       "6926     newberri    0.117209\n",
       "6927        linda    0.117209\n",
       "6928    nonacadem    0.117209\n",
       "\n",
       "[6929 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.sum(axis=0).sort_values(ascending=False).to_frame()\n",
    "new_df.reset_index(inplace=True)\n",
    "new_df.rename(columns = {'index':'word'}, inplace = True)\n",
    "new_df.rename(columns = {0:'Poid'}, inplace = True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_word = new_df.loc[new_df[\"Poid\"] > 70][\"word\"].to_numpy()\n",
    "len(selected_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.01752234, 0.53898566, ..., 0.92175936, 0.83257521,\n",
       "        2.63370226],\n",
       "       [2.01752234, 0.        , 1.47853668, ..., 1.4231289 , 2.20729771,\n",
       "        3.20209213],\n",
       "       [0.53898566, 1.47853668, 0.        , ..., 0.81794518, 0.72876103,\n",
       "        2.38659653],\n",
       "       ...,\n",
       "       [0.92175936, 1.4231289 , 0.81794518, ..., 0.        , 1.11153473,\n",
       "        3.20454172],\n",
       "       [0.83257521, 2.20729771, 0.72876103, ..., 1.11153473, 0.        ,\n",
       "        3.11535756],\n",
       "       [2.63370226, 3.20209213, 2.38659653, ..., 3.20454172, 3.11535756,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = calcule_distances(df[selected_word].to_numpy(), methode = \"manhattan\")\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01171615528055795, 7.728244098387436)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = distances.copy()\n",
    "dist[dist == 0] = 1000\n",
    "dist.min(), distances.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1002\n",
      "417\n",
      "16\n",
      "12\n",
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "clusters, noise = dbscan(distances, 0.4, 5)\n",
    "print(len(clusters), len(noise))\n",
    "for c in clusters:\n",
    "    print(len(c))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amélioratuon mais toujours des résultats non satisfaisant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection en utilisant les fréquences et K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>analyz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>util</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>machin</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>catalogu</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>decis</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>file-manag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>realkatalog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>fig</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>fifty-thre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6698 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Frequence\n",
       "692        analyz         99\n",
       "6633         util         98\n",
       "3784       machin         98\n",
       "1271     catalogu         98\n",
       "1878        decis         97\n",
       "...           ...        ...\n",
       "2584   file-manag          1\n",
       "5186  realkatalog          1\n",
       "2580          fig          1\n",
       "2579   fifty-thre          1\n",
       "0               0          1\n",
       "\n",
       "[6698 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq = fichier_inverse.groupby(\"Word\")[\"Frequence\"].sum().to_frame()\n",
    "df_freq.reset_index(inplace=True)\n",
    "df_freq = df_freq.sort_values(by=[\"Frequence\"]) \n",
    "df_freq = df_freq.reindex(index=df_freq.index[::-1])\n",
    "df_freq = df_freq.loc[df_freq[\"Frequence\"] < 100]\n",
    "df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters = KMeans(n_clusters=20).fit(new_df[\"Poid\"].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732\n",
      "63\n",
      "2\n",
      "148\n",
      "72\n",
      "20\n",
      "2\n",
      "422\n",
      "5\n",
      "27\n",
      "125\n",
      "2822\n",
      "291\n",
      "842\n",
      "8\n",
      "21\n",
      "91\n",
      "193\n",
      "1\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(len(np.where(clusters.labels_ == i)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 1</th>\n",
       "      <th>Cluster 2</th>\n",
       "      <th>Cluster 3</th>\n",
       "      <th>Cluster 4</th>\n",
       "      <th>Cluster 5</th>\n",
       "      <th>Cluster 6</th>\n",
       "      <th>Cluster 7</th>\n",
       "      <th>Cluster 8</th>\n",
       "      <th>Cluster 9</th>\n",
       "      <th>Cluster 10</th>\n",
       "      <th>Cluster 11</th>\n",
       "      <th>Cluster 12</th>\n",
       "      <th>Cluster 13</th>\n",
       "      <th>Cluster 14</th>\n",
       "      <th>Cluster 15</th>\n",
       "      <th>Cluster 16</th>\n",
       "      <th>Cluster 17</th>\n",
       "      <th>Cluster 18</th>\n",
       "      <th>Cluster 19</th>\n",
       "      <th>Cluster 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.215993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.395684</td>\n",
       "      <td>1.191914</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>1.874304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209136</td>\n",
       "      <td>0.413886</td>\n",
       "      <td>1.582325</td>\n",
       "      <td>2.503981</td>\n",
       "      <td>4.388761</td>\n",
       "      <td>0.175460</td>\n",
       "      <td>0.201332</td>\n",
       "      <td>2.575038</td>\n",
       "      <td>2.248579</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.769305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.416998</td>\n",
       "      <td>0.380775</td>\n",
       "      <td>1.438930</td>\n",
       "      <td>0.970487</td>\n",
       "      <td>0.510115</td>\n",
       "      <td>0.444238</td>\n",
       "      <td>1.328241</td>\n",
       "      <td>0.308849</td>\n",
       "      <td>0.909419</td>\n",
       "      <td>0.700764</td>\n",
       "      <td>0.791163</td>\n",
       "      <td>0.746580</td>\n",
       "      <td>0.862228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689825</td>\n",
       "      <td>1.539101</td>\n",
       "      <td>0.56226</td>\n",
       "      <td>0.643950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.570065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.844258</td>\n",
       "      <td>0.537412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217586</td>\n",
       "      <td>0.877327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406869</td>\n",
       "      <td>0.224862</td>\n",
       "      <td>0.861224</td>\n",
       "      <td>1.639981</td>\n",
       "      <td>1.414704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708833</td>\n",
       "      <td>1.151465</td>\n",
       "      <td>0.264048</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.448014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.451863</td>\n",
       "      <td>1.599306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966901</td>\n",
       "      <td>0.471665</td>\n",
       "      <td>0.652862</td>\n",
       "      <td>0.218292</td>\n",
       "      <td>0.452727</td>\n",
       "      <td>0.281121</td>\n",
       "      <td>0.784758</td>\n",
       "      <td>0.564307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.508874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162709</td>\n",
       "      <td>0.750317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.329562</td>\n",
       "      <td>0.56226</td>\n",
       "      <td>1.286366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615811</td>\n",
       "      <td>0.423083</td>\n",
       "      <td>0.521894</td>\n",
       "      <td>1.946135</td>\n",
       "      <td>0.559184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.985242</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>1.349846</td>\n",
       "      <td>2.942192</td>\n",
       "      <td>0.477320</td>\n",
       "      <td>2.574625</td>\n",
       "      <td>1.602553</td>\n",
       "      <td>0.114628</td>\n",
       "      <td>0.307144</td>\n",
       "      <td>1.142059</td>\n",
       "      <td>1.393443</td>\n",
       "      <td>0.09371</td>\n",
       "      <td>1.585796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1.603782</td>\n",
       "      <td>1.250918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.832183</td>\n",
       "      <td>4.362132</td>\n",
       "      <td>0.296780</td>\n",
       "      <td>0.233504</td>\n",
       "      <td>1.749770</td>\n",
       "      <td>0.155383</td>\n",
       "      <td>0.196348</td>\n",
       "      <td>2.086228</td>\n",
       "      <td>0.632930</td>\n",
       "      <td>1.154117</td>\n",
       "      <td>0.477597</td>\n",
       "      <td>0.277922</td>\n",
       "      <td>0.155879</td>\n",
       "      <td>0.806548</td>\n",
       "      <td>3.074385</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.426726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.427247</td>\n",
       "      <td>1.986533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.673228</td>\n",
       "      <td>2.578115</td>\n",
       "      <td>0.388230</td>\n",
       "      <td>0.097293</td>\n",
       "      <td>2.493519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469978</td>\n",
       "      <td>1.023831</td>\n",
       "      <td>1.004761</td>\n",
       "      <td>1.259908</td>\n",
       "      <td>0.386889</td>\n",
       "      <td>0.114628</td>\n",
       "      <td>0.284454</td>\n",
       "      <td>1.148750</td>\n",
       "      <td>0.613108</td>\n",
       "      <td>0.56226</td>\n",
       "      <td>0.851734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>10.130905</td>\n",
       "      <td>1.169119</td>\n",
       "      <td>0.338467</td>\n",
       "      <td>5.481784</td>\n",
       "      <td>0.849697</td>\n",
       "      <td>0.291472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.219168</td>\n",
       "      <td>0.261893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.419047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.247254</td>\n",
       "      <td>3.420452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591262</td>\n",
       "      <td>6.797794</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.395756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.068804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.140331</td>\n",
       "      <td>0.861605</td>\n",
       "      <td>0.992151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.661154</td>\n",
       "      <td>1.062893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.358876</td>\n",
       "      <td>2.504982</td>\n",
       "      <td>0.252204</td>\n",
       "      <td>0.676113</td>\n",
       "      <td>0.885312</td>\n",
       "      <td>2.273069</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>3.960447</td>\n",
       "      <td>0.779308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.734315</td>\n",
       "      <td>0.897039</td>\n",
       "      <td>1.130033</td>\n",
       "      <td>0.533053</td>\n",
       "      <td>0.737593</td>\n",
       "      <td>0.842558</td>\n",
       "      <td>1.953367</td>\n",
       "      <td>2.054499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.879676</td>\n",
       "      <td>0.773777</td>\n",
       "      <td>1.228571</td>\n",
       "      <td>2.429248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.221747</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.858356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cluster 1  Cluster 2  Cluster 3  Cluster 4  Cluster 5  Cluster 6  \\\n",
       "0      0.000000   1.215993   0.000000   0.000000   1.395684   1.191914   \n",
       "1      0.320435   0.416998   0.380775   1.438930   0.970487   0.510115   \n",
       "2      0.000000   1.570065   0.000000   2.844258   0.537412   0.000000   \n",
       "3      4.451863   1.599306   0.000000   0.966901   0.471665   0.652862   \n",
       "4      0.000000   0.615811   0.423083   0.521894   1.946135   0.559184   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1455   1.603782   1.250918   0.000000   2.832183   4.362132   0.296780   \n",
       "1456   0.427247   1.986533   0.000000   1.673228   2.578115   0.388230   \n",
       "1457  10.130905   1.169119   0.338467   5.481784   0.849697   0.291472   \n",
       "1458   0.000000   1.068804   0.000000   1.140331   0.861605   0.992151   \n",
       "1459   3.960447   0.779308   0.000000   2.734315   0.897039   1.130033   \n",
       "\n",
       "      Cluster 7  Cluster 8  Cluster 9  Cluster 10  Cluster 11  Cluster 12  \\\n",
       "0      0.145940   1.874304   0.000000    0.209136    0.413886    1.582325   \n",
       "1      0.444238   1.328241   0.308849    0.909419    0.700764    0.791163   \n",
       "2      0.217586   0.877327   0.000000    0.406869    0.224862    0.861224   \n",
       "3      0.218292   0.452727   0.281121    0.784758    0.564307    0.000000   \n",
       "4      0.000000   4.985242   0.117134    1.349846    2.942192    0.477320   \n",
       "...         ...        ...        ...         ...         ...         ...   \n",
       "1455   0.233504   1.749770   0.155383    0.196348    2.086228    0.632930   \n",
       "1456   0.097293   2.493519   0.000000    0.469978    1.023831    1.004761   \n",
       "1457   0.000000   7.219168   0.261893    0.000000    4.419047    0.000000   \n",
       "1458   0.000000   0.000000   0.258971    0.661154    1.062893    0.000000   \n",
       "1459   0.533053   0.737593   0.842558    1.953367    2.054499    0.000000   \n",
       "\n",
       "      Cluster 13  Cluster 14  Cluster 15  Cluster 16  Cluster 17  Cluster 18  \\\n",
       "0       2.503981    4.388761    0.175460    0.201332    2.575038    2.248579   \n",
       "1       0.746580    0.862228    0.000000    0.000000    0.689825    1.539101   \n",
       "2       1.639981    1.414704    0.000000    0.708833    1.151465    0.264048   \n",
       "3       1.508874    0.000000    0.162709    0.750317    0.000000    1.329562   \n",
       "4       2.574625    1.602553    0.114628    0.307144    1.142059    1.393443   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1455    1.154117    0.477597    0.277922    0.155879    0.806548    3.074385   \n",
       "1456    1.259908    0.386889    0.114628    0.284454    1.148750    0.613108   \n",
       "1457    7.247254    3.420452    0.000000    0.000000    0.591262    6.797794   \n",
       "1458    1.358876    2.504982    0.252204    0.676113    0.885312    2.273069   \n",
       "1459    1.879676    0.773777    1.228571    2.429248    0.000000    1.221747   \n",
       "\n",
       "      Cluster 19  Cluster 20  \n",
       "0        0.00000    0.769305  \n",
       "1        0.56226    0.643950  \n",
       "2        0.00000    1.448014  \n",
       "3        0.56226    1.286366  \n",
       "4        0.09371    1.585796  \n",
       "...          ...         ...  \n",
       "1455     0.00000    1.426726  \n",
       "1456     0.56226    0.851734  \n",
       "1457     0.00000    2.395756  \n",
       "1458     0.00000    0.000000  \n",
       "1459     0.00000    1.858356  \n",
       "\n",
       "[1460 rows x 20 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters = pd.DataFrame()\n",
    "for i in range(20):\n",
    "    words = new_df.iloc[np.where(clusters.labels_ == i)[0]][\"word\"].to_numpy()\n",
    "    df_clusters[\"Cluster \"+str(i+1)] = df[words].sum(axis=1)\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 15.92069722, 16.03282973, ..., 43.24159156,\n",
       "        13.04785871, 27.23675978],\n",
       "       [15.92069722,  0.        , 11.49545345, ..., 43.51838981,\n",
       "        10.78547857, 18.43707675],\n",
       "       [16.03282973, 11.49545345,  0.        , ..., 42.7587429 ,\n",
       "        12.2084499 , 18.23504029],\n",
       "       ...,\n",
       "       [43.24159156, 43.51838981, 42.7587429 , ...,  0.        ,\n",
       "        41.80981724, 40.82209541],\n",
       "       [13.04785871, 10.78547857, 12.2084499 , ..., 41.80981724,\n",
       "         0.        , 18.93179098],\n",
       "       [27.23675978, 18.43707675, 18.23504029, ..., 40.82209541,\n",
       "        18.93179098,  0.        ]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distances = manhattan_distance(df_clusters.to_numpy())\n",
    "cluster_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 62)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters, noise = dbscan(cluster_distances, 15, 3)\n",
    "len(clusters), len(noise)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats non satisfaisants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection en utilisant les transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = open(\"../cisi/CISI.ALL\").read()\n",
    "def split_extraction(documents):\n",
    "    content = documents.split(\".I \") # Split sur le numéro de document\n",
    "    del content[0] # Suppression du premier élément qui est vide\n",
    "\n",
    "    parts = content \n",
    "    data = [] # Liste qui contiendra les données\n",
    "    for part in parts: # Pour chaque document\n",
    "        \n",
    "        temp = part.split(\".T\\n\") # Split sur le titre\n",
    "        if len(temp) == 1 : temp = part.split(\".T \\n\") # Si le titre prend un espace avant de retourner à la ligne\n",
    "        if len(temp) == 1 : temp = part.split(\".T  \\n\") # Si le titre prend deux espaces avant de retourner à la ligne\n",
    "        \n",
    "        del temp[0] # Suppression du premier élément qui est vide\n",
    "        aut_temp = temp[0].split(\".A\\n\") if len(temp[0].split(\".A\\n\")) >= 2 else temp[0].split(\".A \\n\") # Split sur l'auteur (si l'auteur prend un espace avant de retourner à la ligne)\n",
    "        if len(aut_temp) > 2 : # Si le document a plus d'un auteur\n",
    "            while len(aut_temp) != 2: # On supprime l'intégralité des auteurs \n",
    "                del aut_temp[1]\n",
    "        title, temp2 = aut_temp # On récupère le titre et le reste du document\n",
    "        \n",
    "        summary = temp2.split(\".W\\n\")[-1].split(\".X\")[0] # On récupère le résumé et on supprime les références\n",
    "        summary = summary.split(\".W\")[-1] # On re applique un split afin de gérer un cas particulier\n",
    "        data.append([' '.join(title.split()).lower(),' '.join(summary.split()).lower()]) # On ajoute le titre et le résumé dans la liste\n",
    "    return data\n",
    "data = split_extraction(documents)\n",
    "text = \"\"\n",
    "for d in data:\n",
    "    text += ' '.join(d) + \" \" \n",
    "full_text = ''.join(text) + \" \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['period', 'morn', 'night', 'forenoon', 'fortnight', 'phase',\n",
       "       'month', 'week', 'stage', 'era', 'year'], dtype='<U9'),\n",
       "       array(['book', 'workbook', 'encyclopedia', 'reprint', 'pamphlet',\n",
       "       'textbook', 'catalog', 'read', 'handbook'], dtype='<U12'),\n",
       "       array(['scholar', 'plato', 'popper', 'generalist', 'steiner', 'pundit',\n",
       "       'humanist', 'berkeley', 'hartley', 'realist', 'trevelyan',\n",
       "       'historian'], dtype='<U10'),\n",
       "       array(['de', 'il', 'connecticut', 'vermont', 'maryland', 'hawaii',\n",
       "       'georgia', 'sd', 'ia', 'pennsylvania', 'florida', 'indiana',\n",
       "       'colorado', 'minnesota', 'missouri', 'california', 'virginia',\n",
       "       'michigan', 'ct', 'oh', 'ohio'], dtype='<U12'),\n",
       "       array(['luxembourg', 'colombo', 'lusaka', 'kiev', 'moscow', 'vienna',\n",
       "       'rome', 'copenhagen', 'washington', 'london'], dtype='<U10'),\n",
       "       array(['author', 'asimov', 'anderson', 'stephen', 'poe', 'hesiod',\n",
       "       'pushkin', 'fletcher', 'johnson', 'vega', 'coauthor', 'emerson',\n",
       "       'housman', 'mcluhan', 'wilson', 'crane', 'merton', 'writer',\n",
       "       'shepard'], dtype='<U8'),\n",
       "       array(['philadelphia', 'palermo', 'babylon', 'cincinnati', 'abidjan',\n",
       "       'delhi', 'medellin', 'birmingham', 'leningrad', 'gomorrah',\n",
       "       'newark', 'leipzig', 'nice', 'bristol', 'pittsburgh', 'delphi',\n",
       "       'liverpool', 'sheffield', 'assur', 'chicago', 'cleveland'],\n",
       "      dtype='<U12'),\n",
       "       array(['digit', 'tetrad', 'triad', 'ix', 'viii', 'vii', 'vi', 'iv',\n",
       "       'seven', 'eight', 'five', 'iii', 'ii', 'six', 'four', 'three',\n",
       "       'nine', 'two', 'one'], dtype='<U6'),\n",
       "       array(['physician', 'veterinarian', 'dentist', 'doc', 'neurologist',\n",
       "       'doctor', 'extern', 'lister', 'intern'], dtype='<U12'),\n",
       "       array(['metal', 'calcium', 'sr', 'na', 'potassium', 'ti', 'ir', 'iron',\n",
       "       'ba', 'be', 'la', 'ca', 'al'], dtype='<U9')], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "word_clusters = model.encode(full_text)\n",
    "word_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_state = dict()\n",
    "i = 1\n",
    "for wc in word_clusters:\n",
    "    save_state[\"Group\"+str(i)] = wc.tolist()\n",
    "    i+=1\n",
    "\n",
    "with open(\"../groups.json\", \"w\") as write_file:\n",
    "    json.dump(save_state, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['period', 'morn', 'night', 'forenoon', 'fortnight', 'phase',\n",
       "       'month', 'week', 'stage', 'era', 'year'], dtype='<U9'),\n",
       "       array(['book', 'workbook', 'encyclopedia', 'reprint', 'pamphlet',\n",
       "       'textbook', 'catalog', 'read', 'handbook'], dtype='<U12'),\n",
       "       array(['scholar', 'plato', 'popper', 'generalist', 'steiner', 'pundit',\n",
       "       'humanist', 'berkeley', 'hartley', 'realist', 'trevelyan',\n",
       "       'historian'], dtype='<U10'),\n",
       "       array(['de', 'il', 'connecticut', 'vermont', 'maryland', 'hawaii',\n",
       "       'georgia', 'sd', 'ia', 'pennsylvania', 'florida', 'indiana',\n",
       "       'colorado', 'minnesota', 'missouri', 'california', 'virginia',\n",
       "       'michigan', 'ct', 'oh', 'ohio'], dtype='<U12'),\n",
       "       array(['luxembourg', 'colombo', 'lusaka', 'kiev', 'moscow', 'vienna',\n",
       "       'rome', 'copenhagen', 'washington', 'london'], dtype='<U10'),\n",
       "       array(['author', 'asimov', 'anderson', 'stephen', 'poe', 'hesiod',\n",
       "       'pushkin', 'fletcher', 'johnson', 'vega', 'coauthor', 'emerson',\n",
       "       'housman', 'mcluhan', 'wilson', 'crane', 'merton', 'writer',\n",
       "       'shepard'], dtype='<U8'),\n",
       "       array(['philadelphia', 'palermo', 'babylon', 'cincinnati', 'abidjan',\n",
       "       'delhi', 'medellin', 'birmingham', 'leningrad', 'gomorrah',\n",
       "       'newark', 'leipzig', 'nice', 'bristol', 'pittsburgh', 'delphi',\n",
       "       'liverpool', 'sheffield', 'assur', 'chicago', 'cleveland'],\n",
       "      dtype='<U12'),\n",
       "       array(['digit', 'tetrad', 'triad', 'ix', 'viii', 'vii', 'vi', 'iv',\n",
       "       'seven', 'eight', 'five', 'iii', 'ii', 'six', 'four', 'three',\n",
       "       'nine', 'two', 'one'], dtype='<U6'),\n",
       "       array(['physician', 'veterinarian', 'dentist', 'doc', 'neurologist',\n",
       "       'doctor', 'extern', 'lister', 'intern'], dtype='<U12'),\n",
       "       array(['metal', 'calcium', 'sr', 'na', 'potassium', 'ti', 'ir', 'iron',\n",
       "       'ba', 'be', 'la', 'ca', 'al'], dtype='<U9')], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_clusters = list(json.load(open(\"../groups.json\")).values())\n",
    "word_clusters = np.array([np.array(c) for c in word_clusters])\n",
    "word_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 1</th>\n",
       "      <th>Cluster 2</th>\n",
       "      <th>Cluster 3</th>\n",
       "      <th>Cluster 4</th>\n",
       "      <th>Cluster 5</th>\n",
       "      <th>Cluster 6</th>\n",
       "      <th>Cluster 7</th>\n",
       "      <th>Cluster 8</th>\n",
       "      <th>Cluster 9</th>\n",
       "      <th>Cluster 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143404</td>\n",
       "      <td>0.270915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1.850878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.904133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cluster 1  Cluster 2  Cluster 3  Cluster 4  Cluster 5  Cluster 6  \\\n",
       "0      0.000000   0.000000        0.0        0.0        0.0   0.000000   \n",
       "1      0.143404   0.270915        0.0        0.0        0.0   0.000000   \n",
       "2      0.000000   0.000000        0.0        0.0        0.0   0.000000   \n",
       "3      0.000000   0.000000        0.0        0.0        0.0   0.000000   \n",
       "4      0.150689   0.000000        0.0        0.0        0.0   0.000000   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1455   0.000000   0.155383        0.0        0.0        0.0   0.000000   \n",
       "1456   0.000000   0.000000        0.0        0.0        0.0   0.000000   \n",
       "1457   1.850878   0.000000        0.0        0.0        0.0   0.340128   \n",
       "1458   0.000000   0.258971        0.0        0.0        0.0   0.000000   \n",
       "1459   0.904133   0.000000        0.0        0.0        0.0   0.340128   \n",
       "\n",
       "      Cluster 7  Cluster 8  Cluster 9  Cluster 10  \n",
       "0           0.0   0.000000        0.0         0.0  \n",
       "1           0.0   0.185487        0.0         0.0  \n",
       "2           0.0   0.126372        0.0         0.0  \n",
       "3           0.0   0.354757        0.0         0.0  \n",
       "4           0.0   0.123658        0.0         0.0  \n",
       "...         ...        ...        ...         ...  \n",
       "1455        0.0   0.296780        0.0         0.0  \n",
       "1456        0.0   0.123658        0.0         0.0  \n",
       "1457        0.0   0.000000        0.0         0.0  \n",
       "1458        0.0   0.000000        0.0         0.0  \n",
       "1459        0.0   0.000000        0.0         0.0  \n",
       "\n",
       "[1460 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters = pd.DataFrame()\n",
    "i = 1\n",
    "for c in word_clusters:\n",
    "    df_clusters[\"Cluster \"+str(i)] = df[c].sum(axis=1)\n",
    "    i += 1\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.94211934, 0.79439579, ..., 0.85990716, 0.95986786,\n",
       "        0.93106985],\n",
       "       [1.        , 0.73805684, 0.81522626, ..., 0.79508038, 0.79508038,\n",
       "        0.95218339],\n",
       "       [0.9248936 , 0.91205711, 0.72949473, ..., 1.        , 0.84442234,\n",
       "        0.87858377],\n",
       "       ...,\n",
       "       [0.75408656, 0.76757146, 0.71112712, ..., 0.823416  , 0.75504815,\n",
       "        0.91217535],\n",
       "       [1.        , 0.92878937, 0.87523715, ..., 0.98427099, 0.94055683,\n",
       "        1.        ],\n",
       "       [1.        , 0.88525502, 0.9049204 , ..., 1.        , 1.        ,\n",
       "        0.9542612 ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distances = df\n",
    "cluster_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 521\n",
      "231\n",
      "189\n",
      "102\n",
      "137\n",
      "142\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "clusters, noise = dbscan(cluster_distances, 0.6, 200)\n",
    "print(len(clusters), len(noise))\n",
    "for c in clusters:\n",
    "    print(len(c))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification des documents avec Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_inverse_nb = fichier_inverse.copy()\n",
    "fichier_inverse_nb[\"Cluster\"] = -1\n",
    "for c in clusters:\n",
    "    cc = np.array(c, dtype=str)\n",
    "    cc= [\"D\" + item for item in cc]\n",
    "    fichier_inverse_nb[\"Cluster\"].loc[fichier_inverse_nb[\"Document\"].isin(cc)] = clusters.index(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.18</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.7%</th>\n",
       "      <th>000</th>\n",
       "      <th>029</th>\n",
       "      <th>044</th>\n",
       "      <th>054</th>\n",
       "      <th>071</th>\n",
       "      <th>071182</th>\n",
       "      <th>073</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero-on</th>\n",
       "      <th>zhurnal</th>\n",
       "      <th>ziman</th>\n",
       "      <th>zipf</th>\n",
       "      <th>zipfian</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoolog</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>Prob(Cluster)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.248248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.520521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.104104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.050050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.044044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.033033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 6929 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.18       0.5      0.7%       000       029       044       054  \\\n",
       "0  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "1  0.000028  0.000028  0.000028  0.000028  0.000028  0.000028  0.000028   \n",
       "2  0.000130  0.000130  0.000130  0.000130  0.000130  0.000130  0.000130   \n",
       "3  0.000265  0.000265  0.000265  0.000265  0.000265  0.000265  0.000265   \n",
       "4  0.000298  0.000298  0.000298  0.000298  0.000298  0.000298  0.000298   \n",
       "5  0.000460  0.000460  0.000460  0.000460  0.000460  0.000460  0.000460   \n",
       "\n",
       "        071    071182       073  ...      zero   zero-on   zhurnal     ziman  \\\n",
       "0  0.000058  0.000058  0.000058  ...  0.000058  0.000058  0.000058  0.000173   \n",
       "1  0.000028  0.000028  0.000028  ...  0.000142  0.000085  0.000028  0.000028   \n",
       "2  0.000130  0.000130  0.000130  ...  0.000130  0.000130  0.000130  0.000130   \n",
       "3  0.000265  0.000265  0.000265  ...  0.000265  0.000265  0.000531  0.000265   \n",
       "4  0.000298  0.000298  0.000298  ...  0.000298  0.000298  0.000298  0.000298   \n",
       "5  0.000460  0.000460  0.000460  ...  0.000460  0.000460  0.000460  0.000460   \n",
       "\n",
       "       zipf   zipfian      zone    zoolog  zuckerman  Prob(Cluster)  \n",
       "0  0.000058  0.000058  0.000173  0.000058   0.000058       0.248248  \n",
       "1  0.000227  0.000057  0.000028  0.000028   0.000028       0.520521  \n",
       "2  0.000261  0.000130  0.000130  0.000130   0.000130       0.104104  \n",
       "3  0.000265  0.000265  0.000265  0.000265   0.000531       0.050050  \n",
       "4  0.000298  0.000298  0.000298  0.000298   0.000298       0.044044  \n",
       "5  0.000460  0.000460  0.000460  0.000460   0.000460       0.033033  \n",
       "\n",
       "[6 rows x 6929 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_nb = 0\n",
    "\n",
    "for c in clusters:\n",
    "    docs_nb = docs_nb + len(c)\n",
    "unique_terms =sorted(list(df.columns))[1:] # On récupère les termes uniques\n",
    "df_nb = pd.DataFrame(columns = unique_terms)\n",
    "freq_cluster_word = fichier_inverse_nb.groupby([\"Cluster\", \"Word\"])[\"Frequence\"].sum().to_frame()\n",
    "freq_cluster_word.reset_index(inplace=True)\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    df_nb.loc[i] = np.zeros(len(unique_terms))\n",
    "    freq_word = freq_cluster_word.loc[freq_cluster_word['Cluster'] == i]\n",
    "    freq_word = freq_word.loc[freq_word[\"Word\"].isin(list(df_clean.columns))] # On supprime les colonnes contenant des chiffres\n",
    "    df_nb.loc[i][freq_word[\"Word\"]] = freq_word[\"Frequence\"].to_numpy()\n",
    "    df_nb.loc[i] += 1 \n",
    "    df_nb.loc[i] /= freq_word[\"Frequence\"].sum()\n",
    "proba = []\n",
    "for i in range(len(clusters)):\n",
    "    proba.append(len(clusters[i]) / docs_nb)\n",
    "df_nb[\"Prob(Cluster)\"] = proba\n",
    "df_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>descript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>titl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>Q112</td>\n",
       "      <td>algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>Q112</td>\n",
       "      <td>compar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>Q112</td>\n",
       "      <td>previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Q112</td>\n",
       "      <td>describ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>Q112</td>\n",
       "      <td>procedur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5193 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Query       Word\n",
       "0       Q1    problem\n",
       "1       Q1    concern\n",
       "2       Q1       make\n",
       "3       Q1   descript\n",
       "4       Q1       titl\n",
       "...    ...        ...\n",
       "5188  Q112  algorithm\n",
       "5189  Q112     compar\n",
       "5190  Q112   previous\n",
       "5191  Q112    describ\n",
       "5192  Q112   procedur\n",
       "\n",
       "[5193 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_queries = pd.read_csv(\"../info_queries.csv\")\n",
    "info_queries.drop(columns = info_queries.columns[0], axis = 1, inplace= True)\n",
    "info_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>D28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>D35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>D38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>D42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>D43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>Q111</td>\n",
       "      <td>D422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>Q111</td>\n",
       "      <td>D448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>Q111</td>\n",
       "      <td>D485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>Q111</td>\n",
       "      <td>D503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>Q111</td>\n",
       "      <td>D509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Query Document\n",
       "0       Q1      D28\n",
       "1       Q1      D35\n",
       "2       Q1      D38\n",
       "3       Q1      D42\n",
       "4       Q1      D43\n",
       "...    ...      ...\n",
       "3109  Q111     D422\n",
       "3110  Q111     D448\n",
       "3111  Q111     D485\n",
       "3112  Q111     D503\n",
       "3113  Q111     D509\n",
       "\n",
       "[3114 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(\"../csv_docs/evaluation.csv\")\n",
    "eval_df = eval_df.drop(\"Unnamed: 0\", axis=1)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction recréant l'algorithme Naive Bayes\n",
    "def naive_bayes(info_queries, df):\n",
    "    number_cols = [x for x in df.columns if re.search(r'\\d', x)] # On récupère les colonnes contenant des nombres\n",
    "    df_clean = df.copy()  # On crée une copie du dataframe\n",
    "    for c in number_cols: \n",
    "        df_clean.drop(c, axis=1, inplace=True) # On supprime les colonnes contenant des nombres\n",
    "    queries = info_queries[\"Query\"].unique() # On récupère les requêtes\n",
    "    y_pred = [] # On initialise la liste des prédictions\n",
    "    for q in queries: # Pour chaque requête\n",
    "        probas = [] # On initialise la liste des probabilités\n",
    "        for i in range(len(df)): # Pour chaque document\n",
    "            iq = info_queries.loc[info_queries[\"Query\"] == q] # On récupère les informations de la requête\n",
    "            probas.append(df.loc[i][iq.loc[iq[\"Word\"].isin(list(df_clean.columns))][\"Word\"].to_numpy()].prod() * df.loc[i][\"Prob(Cluster)\"]) # On calcule la probabilité du document pour la requête\n",
    "        y_pred.append([q, np.argmax(probas)]) # On ajoute la prédiction pour la requête\n",
    "    return y_pred # On retourne la liste des prédictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application de notre SRI et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>D256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>D261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>D303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>D367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>D379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>D402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>D446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>D450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>D500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>D506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>D536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>D550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>D573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>D595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>D605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>D622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>D642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>D653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>D679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>D689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>D693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>D780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>D803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>D805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>D826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>D841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>D849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>D883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>D921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>D960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>D1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>D1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>D1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>D1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>D1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>D1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>D1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>D1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>D1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>D1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>D1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>D1454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document\n",
       "0       D10\n",
       "1       D28\n",
       "2       D35\n",
       "3       D38\n",
       "4       D42\n",
       "5       D43\n",
       "6       D49\n",
       "7       D52\n",
       "8       D65\n",
       "9       D71\n",
       "10      D76\n",
       "11      D85\n",
       "12      D86\n",
       "13     D138\n",
       "14     D150\n",
       "15     D169\n",
       "16     D244\n",
       "17     D256\n",
       "18     D261\n",
       "19     D278\n",
       "20     D303\n",
       "21     D367\n",
       "22     D379\n",
       "23     D402\n",
       "24     D446\n",
       "25     D450\n",
       "26     D500\n",
       "27     D506\n",
       "28     D536\n",
       "29     D550\n",
       "30     D573\n",
       "31     D595\n",
       "32     D605\n",
       "33     D622\n",
       "34     D642\n",
       "35     D653\n",
       "36     D679\n",
       "37     D689\n",
       "38     D693\n",
       "39     D780\n",
       "40     D803\n",
       "41     D805\n",
       "42     D826\n",
       "43     D841\n",
       "44     D849\n",
       "45     D883\n",
       "46     D921\n",
       "47     D960\n",
       "48    D1019\n",
       "49    D1060\n",
       "50    D1077\n",
       "51    D1186\n",
       "52    D1238\n",
       "53    D1291\n",
       "54    D1339\n",
       "55    D1363\n",
       "56    D1368\n",
       "57    D1396\n",
       "58    D1421\n",
       "59    D1454"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonction représentant le fonctionnement de notre SRI basé text mining\n",
    "def text_mining_sri(query, info_queries, df, fichier_inverse, radius, min_pts):\n",
    "    cluster_distances = pd.read_csv(\"../csv_docs/distances.csv\").to_numpy() # On récupère les distances entre les documents\n",
    "    clusters, noise = dbscan(cluster_distances, radius, min_pts) # On récupère les clusters et le bruit\n",
    "    fichier_inverse_nb = fichier_inverse.copy() # On crée une copie du fichier inverse\n",
    "    fichier_inverse_nb[\"Cluster\"] = -1 # On initialise la colonne Cluster à -1\n",
    "    for c in clusters: # Pour chaque cluster\n",
    "        cc = np.array(c, dtype=str) # On convertit les numéros de documents en chaînes de caractères\n",
    "        cc= [\"D\" + item for item in cc] # On ajoute un D devant chaque numéro de document\n",
    "        fichier_inverse_nb[\"Cluster\"].loc[fichier_inverse_nb[\"Document\"].isin(cc)] = clusters.index(c) # On change la valeur -1 par le numéro du cluster pour indiquer que le document appartient à ce cluster\n",
    "    docs_nb = 0 # On initialise le nombre de documents\n",
    "    for c in clusters: # Pour chaque cluster\n",
    "        docs_nb = docs_nb + len(c) # On ajoute le nombre de documents du cluster au nombre total de documents\n",
    "    unique_terms =sorted(list(df.columns))[1:] # On récupère les termes uniques\n",
    "    df_nb = pd.DataFrame(columns = unique_terms) # On crée un dataframe contenant les termes uniques\n",
    "    freq_cluster_word = fichier_inverse_nb.groupby([\"Cluster\", \"Word\"])[\"Frequence\"].sum().to_frame() # On récupère la fréquence des termes par cluster\n",
    "    freq_cluster_word.reset_index(inplace=True) # On réinitialise l'index\n",
    "    number_cols = [x for x in df.columns if re.search(r'\\d', x)] # On récupère les colonnes contenant des nombres\n",
    "    df_clean = df.copy()  # On crée une copie du dataframe\n",
    "    for c in number_cols:  \n",
    "        df_clean.drop(c, axis=1, inplace=True) # On supprime les colonnes contenant des nombres\n",
    "    for i in range(len(clusters)): # Pour chaque cluster\n",
    "        df_nb.loc[i] = np.zeros(len(unique_terms)) # On initialise la ligne du cluster à 0\n",
    "        freq_word = freq_cluster_word.loc[freq_cluster_word['Cluster'] == i] # On récupère les termes du cluster\n",
    "        freq_word = freq_word.loc[freq_word[\"Word\"].isin(list(df_clean.columns))] # On supprime les colonnes contenant des chiffres\n",
    "        df_nb.loc[i][freq_word[\"Word\"]] = freq_word[\"Frequence\"].to_numpy() # On ajoute la fréquence des termes du cluster\n",
    "        df_nb.loc[i] += 1  # On ajoute 1 à chaque terme du cluster\n",
    "        df_nb.loc[i] /= freq_word[\"Frequence\"].sum() # On divise chaque terme du cluster par la somme des fréquences du cluster\n",
    "    proba = [] # On initialise la liste des probabilités\n",
    "    for i in range(len(clusters)): # Pour chaque cluster\n",
    "        proba.append(len(clusters[i]) / docs_nb) # On calcule la probabilité du cluster\n",
    "    df_nb[\"Prob(Cluster)\"] = proba # On ajoute la probabilité du cluster au dataframe\n",
    "    y_pred = naive_bayes(info_queries.loc[info_queries[\"Query\"] == query], df_nb)[0][1] # On récupère le cluster prédit par Naive Bayes\n",
    "\n",
    "    y_pred = sorted(y_pred) # On trie la liste des prédictions\n",
    "    y_pred = [\"D\"+str(x) for x in y_pred] # On ajoute un D devant chaque numéro de document\n",
    "    if y_pred[0] == \"D0\": y_pred = y_pred[1:] # On supprime le document D0 s'il est présent\n",
    "\n",
    "    return pd.DataFrame(y_pred, columns = [\"Document\"]) # On retourne la liste des prédictions\n",
    "\n",
    "text_mining_sri(\"Q1\", info_queries, df, fichier_inverse, 0.6, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Rappel</th>\n",
       "      <th>F-Mesure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.018506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.030178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>0.016461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Q108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Q109</td>\n",
       "      <td>0.048697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.092871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Q110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Q111</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Q112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Query  Precision  Rappel  F-Mesure\n",
       "0      Q1   0.034860     1.0  0.067371\n",
       "1      Q2   0.018506     1.0  0.036339\n",
       "2      Q3   0.030178     1.0  0.058589\n",
       "3      Q4   0.005487     1.0  0.010914\n",
       "4      Q5   0.016461     1.0  0.032389\n",
       "..    ...        ...     ...       ...\n",
       "107  Q108   0.000000     0.0  0.000000\n",
       "108  Q109   0.048697     1.0  0.092871\n",
       "109  Q110   0.000000     0.0  0.000000\n",
       "110  Q111   0.004115     1.0  0.008197\n",
       "111  Q112   0.000000     0.0  0.000000\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "for query in info_queries[\"Query\"].unique():\n",
    "    tm_result = text_mining_sri(query, info_queries, df, fichier_inverse, 0.6, 200)\n",
    "    p, p5, p10, r, f = compute_metrics(query, eval_df, tm_result)\n",
    "    metrics.append([query, p, r, f])\n",
    "metrics = pd.DataFrame(metrics, columns=[\"Query\", \"Precision\", \"Rappel\", \"F-Mesure\"])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(\"../csv_docs/tm_metrics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59e7fbdb10f88ebb840e0eae9f7068b500ae2fc1cd1508cf05034406aceb4604"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
